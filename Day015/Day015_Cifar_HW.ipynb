{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 135s 1us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis = (0, 1, 2, 3))\n",
    "        std = np.std(X_train, axis = (0, 1, 2, 3))\n",
    "        X_train = (X_train-mean) / (std + 1e-7)\n",
    "        X_test = (X_test-mean) / (std + 1e-7) \n",
    "        return X_train, X_test, mean, std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train, std_train = normalize(x_train, x_test)\n",
    "\n",
    "# mean_train, std_train －> input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of x_train: 50000\n",
      "num of x_test: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"num of x_train:\", len(x_train))\n",
    "print(\"num of x_test:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot = OneHotEncoder()\n",
    "y_train = one_hot.fit_transform(y_train).toarray()\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of y_train: 50000\n",
      "num of y_test: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"num of y_train:\", len(y_train))\n",
    "print(\"num of y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 552,310\n",
      "Trainable params: 552,182\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INTEL\\Desktop\\cvdl\\cvdl_opencv\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "C:\\Users\\INTEL\\Desktop\\cvdl\\cvdl_opencv\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#卷積組合\n",
    "# classifier.add(Convolution2D('自己設計參數')) # 32,3,3,input_shape=(32,32,3),activation='relu'\n",
    "# classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), input_shape=(32, 32, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation(\"relu\"))\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "#卷積組合\n",
    "# classifier.add(Convolution2D('自己設計參數'))\n",
    "# classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "# classifier.add(Dense('自己設計FC層參數')) #output_dim=100, activation=relu\n",
    "classifier.add(Dense(output_dim = 100, activation = \"relu\"))\n",
    "\n",
    "#輸出\n",
    "# classifier.add(Dense(output_dim=10,activation='輸出函數應該用什麼？'))\n",
    "classifier.add(Dense(output_dim = 10,activation=\"relu\"))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.6165 - accuracy: 0.2801\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.9471 - accuracy: 0.3402\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.8790 - accuracy: 0.3751\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0391 - accuracy: 0.3170\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0595 - accuracy: 0.2639\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.9666 - accuracy: 0.2933\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 50s 994us/step - loss: 1.8660 - accuracy: 0.3542\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 49s 978us/step - loss: 1.8871 - accuracy: 0.3543\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 49s 981us/step - loss: 1.8227 - accuracy: 0.3672\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.7636 - accuracy: 0.4133\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.7191 - accuracy: 0.4244\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.8112 - accuracy: 0.3654\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.6748 - accuracy: 0.4361\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.7797 - accuracy: 0.4128\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.6667 - accuracy: 0.4411\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.6485 - accuracy: 0.4637\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.6519 - accuracy: 0.4344\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 49s 987us/step - loss: 1.5968 - accuracy: 0.4744\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.5733 - accuracy: 0.4830\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.7363 - accuracy: 0.4463\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.7323 - accuracy: 0.4159\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.6101 - accuracy: 0.4578\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.5924 - accuracy: 0.4762\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.6911 - accuracy: 0.4415\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.6527 - accuracy: 0.4570\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 1.5647 - accuracy: 0.4976\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 49s 990us/step - loss: 1.6071 - accuracy: 0.4836\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.6240 - accuracy: 0.4797\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.5302 - accuracy: 0.5038\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.5287 - accuracy: 0.5010\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.4796 - accuracy: 0.5220\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.6645 - accuracy: 0.4573\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.4891 - accuracy: 0.5229\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 49s 980us/step - loss: 1.5087 - accuracy: 0.5287\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 49s 978us/step - loss: 1.5602 - accuracy: 0.5004\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.4737 - accuracy: 0.5195\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 49s 988us/step - loss: 1.4249 - accuracy: 0.5436\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.4388 - accuracy: 0.5437\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.4621 - accuracy: 0.5295\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.4974 - accuracy: 0.5213\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 49s 979us/step - loss: 1.4956 - accuracy: 0.5259\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 49s 979us/step - loss: 1.4466 - accuracy: 0.5427\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.3780 - accuracy: 0.5541\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.3658 - accuracy: 0.5635\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.6011 - accuracy: 0.4911\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.5415 - accuracy: 0.4663\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 49s 977us/step - loss: 1.4404 - accuracy: 0.5240\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 49s 978us/step - loss: 1.4342 - accuracy: 0.5356\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 49s 979us/step - loss: 1.3760 - accuracy: 0.5487\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.3335 - accuracy: 0.5594\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.57 - 49s 976us/step - loss: 1.2964 - accuracy: 0.5743\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.3625 - accuracy: 0.5589\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.3327 - accuracy: 0.5681\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 49s 976us/step - loss: 1.3634 - accuracy: 0.5522\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 49s 975us/step - loss: 1.2903 - accuracy: 0.5773\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 49s 973us/step - loss: 1.2533 - accuracy: 0.5936\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 49s 973us/step - loss: 1.3872 - accuracy: 0.5365\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 49s 981us/step - loss: 1.3149 - accuracy: 0.5704\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 49s 977us/step - loss: 1.3033 - accuracy: 0.5692\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 49s 978us/step - loss: 1.2480 - accuracy: 0.5896\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.4323 - accuracy: 0.5500\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3886 - accuracy: 0.5501\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.2868 - accuracy: 0.5745\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.2335 - accuracy: 0.5990\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.2037 - accuracy: 0.6115\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.1929 - accuracy: 0.6190\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.2084 - accuracy: 0.6171\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 1.4252 - accuracy: 0.5618\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.3074 - accuracy: 0.5682\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.4608 - accuracy: 0.5447\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.3534 - accuracy: 0.5532\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.2184 - accuracy: 0.6028\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.1762 - accuracy: 0.6189\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 49s 973us/step - loss: 1.1483 - accuracy: 0.6274\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.1527 - accuracy: 0.6284\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 49s 973us/step - loss: 1.1829 - accuracy: 0.6121\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.2279 - accuracy: 0.6073\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.4011 - accuracy: 0.5525\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 49s 973us/step - loss: 1.3891 - accuracy: 0.5515\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.1948 - accuracy: 0.6104\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.1698 - accuracy: 0.6177\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2168 - accuracy: 0.6091\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.62 - 49s 971us/step - loss: 1.1481 - accuracy: 0.6236\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.3063 - accuracy: 0.5924\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.1868 - accuracy: 0.6158\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 49s 970us/step - loss: 1.4453 - accuracy: 0.5419\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 48s 969us/step - loss: 1.2691 - accuracy: 0.5884\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2255 - accuracy: 0.6010\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2549 - accuracy: 0.5892\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2434 - accuracy: 0.5937\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.3267 - accuracy: 0.5699\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.4101 - accuracy: 0.5470\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 48s 970us/step - loss: 1.2982 - accuracy: 0.5742\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2306 - accuracy: 0.6022\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 49s 972us/step - loss: 1.1858 - accuracy: 0.6096\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.1211 - accuracy: 0.6313\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2165 - accuracy: 0.6169\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2428 - accuracy: 0.6035\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2427 - accuracy: 0.6031\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 1.2652 - accuracy: 0.5851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21a53ac8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train, y_train, batch_size = 100, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.      ,   0.      , 236.79971 , 185.0086  , 401.2982  ,\n",
       "         46.215996, 209.16759 , 213.11108 , 125.67445 , 250.39572 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example = (np.zeros(shape = (1, 32, 32, 3)) - mean_train) / (std_train + 1e-7)\n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvdl",
   "language": "python",
   "name": "cvdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
